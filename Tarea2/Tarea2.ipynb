{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:300%; background-color:pink; color:blue; text-align:center;line-height : 80px; margin : 0; padding : 0;\">\n",
    "Tarea 11: Algoritmo SIFT</p>\n",
    "<p style=\"font-size:240%; background-color:pink; color:red; text-align:center;line-height : 60px; margin : 0; padding : 0;\">\n",
    "Técnicas de Inteligencia Artificial - Visión de Máquina</p1>\n",
    "\n",
    "<p style=\"font-size:200%; text-align:center; line-height : 40px;  margin-top : 0; margin-bottom : 0; \"> <br> Eduardo Garnica Aza</p>\n",
    "<p style=\"font-size:180%; text-align:center; line-height : 30px;  margin-top : 0; margin-bottom : 0; \"> <br><br>INGENIERIA MECATRONICA</p>\n",
    "<p style=\"font-size:180%; text-align:center; line-height : 30px; margin-top : 0; \"> Facultad de Ingeniería</p>\n",
    "<p style=\"font-size:160%; text-align:center; line-height : 30px; margin-top : 0; \"> Universidad Nacional de Colombia Sede Bogotá</p>\n",
    "<br>\n",
    "<p style=\"font-size:160%; text-align:center; line-height : 30px; margin-top : 0; \"> <br>28 de abril de 2022</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo SIFT (Scale-invariant feature transform)\n",
    "\n",
    "Este algoritmo es usado en aplicaciones de visión-máquina para hallar la detección de características o puntos de interés de las imagenes estudiadas, fue patentado por David Lowe en 2004. \n",
    "\n",
    "La premisa principal u objetivo del mismo es hallar puntos relevantes en cuanto a la cantidad de información de su entorno, el algoritmo como su nombre lo indica es invariante pero no solamente a escalado, también a rotaciones, es decir que sin importar si la imagen se rota o escala encontrará los puntos de interés de la misma, estos puntos son filtrados también para no obtener repeticiones de los mismos para así garantizar una detección con exactitud, presición y confiabilidad.\n",
    "\n",
    "- Se presenta un ejemplo de este algoritmo, en el cual se detectan los puntos y posteriormente se grafican para ver cuales son estos puntos de interes, así mismo se unen con una linea entre los puntos que son equivalentes en la imagen original y la rotada/escalada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librerias\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importe de imagenes y creación de un objeto SIFT para citar sus métodos posteriormente\n",
    "imgname1 = 'Walter.jpg'\n",
    "imgname2 = 'WalterOG.jpg'\n",
    "\n",
    "sift = cv2.SIFT_create()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se hace escala de grises\n",
    "img1 = cv2.imread(imgname1)\n",
    "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY) # Procesamiento de imagen en escala de grises\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)   #des es el descriptor\n",
    "\n",
    "img2 = cv2.imread(imgname2)\n",
    "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)# Procesamiento de imagen en escala de grises\n",
    "kp2, des2 = sift.detectAndCompute(img2,None)  #des es el descriptor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "hmerge = np.hstack((gray1, gray2)) #Concatenación horizontal\n",
    "cv2.imshow(\"gray\", hmerge) #Mosaico se muestra en gris\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dibuja los puntos caracteristicos encontrados anteriormente\n",
    "img3 = cv2.drawKeypoints(img1,kp1,img1,color=(255,0,255)) # Dibuje los puntos característicos y muéstrelos como círculos rojos\n",
    "img4 = cv2.drawKeypoints(img2,kp2,img2,color=(255,0,255)) # Dibuje los puntos característicos y muéstrelos como círculos rojos\n",
    "hmerge = np.hstack((img3, img4)) #Concatenación horizontal\n",
    "cv2.imshow(\"point\", img3) #Mosaico se muestra en gris\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow(\"point\", img4) #Mosaico se muestra en gris\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritmo para filtrar puntos que estén muy cerca entre sí\n",
    "\n",
    "Nota: si se usa la variable \"matches\" en vez del arreglo \"good\" en la primera línea del bloque 11 se verán todos los puntos tomados y su cercanía y repetición entre sí\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# BFMatcher resuelve el partido\n",
    "bf = cv2.BFMatcher()\n",
    "matches = bf.knnMatch(des1,des2, k=2)\n",
    "# Ajustar relación\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.75*n.distance:\n",
    "        good.append([m])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impresión final de muestra para la relación entre puntos, se hace impresión de concatenación, es posible que no se vea la imagen completa debido a su ancho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img5 = cv2.drawMatchesKnn(img1,kp1,img2,kp2,good,None,flags=2)\n",
    "cv2.imshow(\"BFmatch\", img5)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codigo tomado de: https://programmerclick.com/article/84931129402/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observaciones finales\n",
    "\n",
    "- Como observación final se puede decir que este algoritmo es completamente efectivo para la detección de puntos de interés en las imagenes, además de ser robusto debido a que es invariante a escala y rotación\n",
    "- Puede que no sea tan amigable computacionalmente hablando, pero es optimo para las aplicaciones propuestas\n",
    "- Se ve que debido a todos los procesos que se hacen toma tiempo en ejecutarse este algoritmo, por ejemplo la implementación de diferencia gaussiana, matriz hessiana para el calculo de curvaturas y la series de Taylor para refinar la precisión de la escala."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e94cf552f7b676573e394eb0ddedb229e06e8df3695a5317dfa8ca16d91c45de"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
